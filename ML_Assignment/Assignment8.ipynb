{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee14a8fc-63b4-46e9-99a5-d29ac636a0a3",
   "metadata": {},
   "source": [
    "1. What exactly is a feature? Give an example to illustrate your point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f74157-bdac-4608-8789-8b8db84cc9ef",
   "metadata": {},
   "source": [
    "Ans: Features are the basic building blocks of datasets. The quality of the features in your dataset has a major impact on the quality of the insights you will gain when you use that dataset for machine learning.\n",
    "\n",
    "Additionally, different business problems within the same industry do not necessarily require the same features, which is why it is important to have a strong understanding of the business goals of your data science project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d4bb9-5b67-437a-9521-1b9aa3a69869",
   "metadata": {},
   "source": [
    "In the context of machine learning, a feature refers to an individual measurable property or characteristic of a data point that is used as input for a model to make predictions or perform analysis. Features are used to represent the relevant information or patterns in the data that can help the model learn and make accurate predictions.\n",
    "\n",
    "Features can be various types of data, such as numerical, categorical, or text-based. They provide information about the attributes or properties of the data points being analyzed. Here's an example to illustrate the concept:\n",
    "\n",
    "Example :Suppose we want to build a model to predict housing prices. In this case, the features could include:\n",
    "\n",
    "    1. Size of the house (numerical feature): This feature represents the area or square footage of the house, which is a numerical value.\n",
    "\n",
    "    2. Number of bedrooms (numerical feature): This feature indicates the count of bedrooms in the house.\n",
    "\n",
    "    3. Location (categorical feature): This feature represents the geographical location of the house and could have categories like \"suburban,\" \"urban,\" or \"rural.\"\n",
    "\n",
    "    4. Age of the house (numerical feature): This feature denotes the number of years since the house was built.\n",
    "\n",
    "    5. Proximity to amenities (numerical feature): This feature measures the distance to amenities like schools, parks, or shopping centers.\n",
    "\n",
    "    6. House style (categorical feature): This feature captures the architectural style of the house, such as \"colonial,\" \"ranch,\" or \"split-level.\"\n",
    "\n",
    "Each of these features provides important information that can influence the predicted housing price. By combining and analyzing these features, the model can learn the relationships and patterns that drive housing prices, enabling it to make predictions on new, unseen data points based on their feature values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00066c95-951d-40b6-bfcd-c24085abc0b0",
   "metadata": {},
   "source": [
    "2. What are the various circumstances in which feature construction is required?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7082b0-673f-493b-9e3b-0ad81b905912",
   "metadata": {},
   "source": [
    "Ans: The features in your data will directly influence the predictive models you use and the results you can achieve. Your results are dependent on many inter-dependent properties. You need great features that describe the structures inherent in your data. Better features means flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7d4c3-5bd7-4334-a9bf-c3486b871210",
   "metadata": {},
   "source": [
    "3. Describe how nominal variables are encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2fa6cb-187c-45d4-b2ec-657916226c4a",
   "metadata": {},
   "source": [
    "Ans: Nominal data is made of discrete values with no numerical relationship between the different categories — mean and median are meaningless. Animal species is one example. For example, pig is not higher than bird and lower than fish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a281b-a40a-4b30-ae3f-84e1ede9805f",
   "metadata": {},
   "source": [
    "4. Describe how numeric features are converted to categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afed3a-65df-461c-9c7e-b04af0a932cd",
   "metadata": {},
   "source": [
    "Ans: Converting categorical features into numeric features using domain knowledge. For example, we are given a list of countries and say we know the distance to these countries from India then we can replace it with distance from India. So, every country can be represented as its distance from India."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f361a32-8139-48a3-82d8-f6ef1a27e425",
   "metadata": {},
   "source": [
    "5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69ff9c-3840-46a2-87ae-75ef086f2014",
   "metadata": {},
   "source": [
    "Ans: Wrapper methods measure the “usefulness” of features based on the classifier performance. In contrast, the filter methods pick up the intrinsic properties of the features (i.e., the “relevance” of the features) measured via univariate statistics instead of cross-validation performance.\n",
    "\n",
    "The wrapper classification algorithms with joint dimensionality reduction and classification can also be used but these methods have high computation cost, lower discriminative power. Moreover, these methods depend on the efficient selection of classifiers for obtaining high accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b6303-820f-4baa-bc63-756bb773d4b1",
   "metadata": {},
   "source": [
    "6. When is a feature considered irrelevant? What can be said to quantify it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a07770-53df-4be7-9e40-4fd0ff8bf883",
   "metadata": {},
   "source": [
    "Ans: Features are considered relevant if they are either strongly or weakly relevant, and are considered irrelevant otherwise.\n",
    "\n",
    "Irrelevant features can never contribute to prediction accuracy, by definition. Also to quantify it we need to first check the list of features, There are three types of feature selection:\n",
    "\n",
    "Wrapper methods (forward, backward, and stepwise selection)\n",
    "Filter methods (ANOVA, Pearson correlation, variance thresholding)\n",
    "Embedded methods (Lasso, Ridge, Decision Tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16878d9-8d72-4df0-b58d-b253a0f974fd",
   "metadata": {},
   "source": [
    "7. When is a function considered redundant? What criteria are used to identify features that could be redundant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a4140-709f-4460-94e0-0f1f98543088",
   "metadata": {},
   "source": [
    "Ans: If two features {X1, X2} are highly correlated, then the two features become redundant features since they have same information in terms of correlation measure. In other words, the correlation measure provides statistical association between any given a pair of features.\n",
    "\n",
    "Minimum redundancy feature selection is an algorithm frequently used in a method to accurately identify characteristics of genes and phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d4bc4d-d781-446a-9dc3-66bd07d2c42e",
   "metadata": {},
   "source": [
    "8. What are the various distance measurements used to determine feature similarity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec67f621-14a6-4b56-8ffe-e23d174f2182",
   "metadata": {},
   "source": [
    "Ans: Four of the most commonly used distance measures in machine learning are as follows:\n",
    "\n",
    "    a) Hamming Distance.\n",
    "    b) Euclidean Distance\n",
    "    c) Manhattan Distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439dbb77-fd6e-426c-8ae2-99fa007a85a0",
   "metadata": {},
   "source": [
    "9. State difference between Euclidean and Manhattan distances?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf02ac6e-ea0f-48a3-8a87-3e4d26020114",
   "metadata": {},
   "source": [
    "Ans: Euclidean & Hamming distances are used to measure similarity or dissimilarity between two sequences. Euclidean distance is extensively applied in analysis of convolutional codes and Trellis codes.\n",
    "\n",
    "Hamming distance is frequently encountered in the analysis of block codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f86380-f9c4-44b8-a262-d28da1a9d22e",
   "metadata": {},
   "source": [
    "10. Distinguish between feature transformation and feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b03f9-10e3-406b-b5ba-6e320988e947",
   "metadata": {},
   "source": [
    "Ans: Feature selection is for filtering irrelevant or redundant features from your dataset. The key difference between feature selection and extraction is that feature selection keeps a subset of the original features while feature extraction creates brand new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d94d83-a0dd-4794-87b2-68f6382b588d",
   "metadata": {},
   "source": [
    "11. Make brief notes on any two of the following:\n",
    "\n",
    "    1. SVD (Standard Variable Diameter Diameter)\n",
    "    2. Collection of features using a hybrid approach\n",
    "    3. The width of the silhouette\n",
    "    4. Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72234a7d-b7ec-4fe4-a784-fcd9152d9f17",
   "metadata": {},
   "source": [
    "Ans: notes :\n",
    "1. SVD (Standard Variable Diameter Diameter):\n",
    "The term \"SVD\" does not correspond to the commonly known abbreviation in the context of machine learning or data analysis. It seems to be a typo or an incorrect acronym. Please provide more information or clarify the intended meaning to provide a relevant response.\n",
    "\n",
    "2. Collection of features using a hybrid approach:\n",
    "In machine learning, the collection of features refers to the process of selecting and gathering the relevant variables or attributes that can effectively represent the data and contribute to the learning task. A hybrid approach in feature collection involves combining multiple techniques or methods to obtain a comprehensive set of features.\n",
    "\n",
    "For example, in a hybrid feature collection approach, one might utilize domain knowledge and expert input to identify relevant features, perform statistical analysis to identify statistically significant variables, employ automatic feature selection algorithms like Recursive Feature Elimination (RFE) or Lasso regression, and utilize text mining techniques for extracting features from textual data. The goal is to leverage the strengths of different approaches to obtain a diverse and informative set of features for the machine learning model.\n",
    "\n",
    "3. The width of the silhouette:\n",
    "The width of the silhouette is a measure used in cluster analysis to assess the quality of clustering results. It quantifies how well each data point fits into its assigned cluster and how distinct the clusters are from one another.\n",
    "\n",
    "The silhouette width is calculated for each data point and ranges from -1 to 1. A value close to 1 indicates that the data point is well-matched to its own cluster and clearly separated from other clusters. A value close to -1 suggests that the data point may have been assigned to the wrong cluster, and the neighboring clusters are more similar to the point. A value around 0 indicates that the data point is on or very close to the decision boundary between clusters.\n",
    "\n",
    "The average silhouette width across all data points is often used as an overall measure of the clustering quality. A higher average silhouette width indicates better-defined and well-separated clusters.\n",
    "\n",
    "4. Receiver Operating Characteristic (ROC) Curve:\n",
    "The Receiver Operating Characteristic curve, or ROC curve, is a graphical representation that illustrates the performance of a binary classification model at different discrimination thresholds. It shows the trade-off between the true positive rate (sensitivity or recall) and the false positive rate as the classification threshold is varied.\n",
    "\n",
    "The ROC curve plots the true positive rate (TPR) on the y-axis and the false positive rate (FPR) on the x-axis. Each point on the curve corresponds to a specific threshold for classifying positive and negative instances. The curve provides insights into the model's ability to distinguish between the two classes across different threshold settings.\n",
    "\n",
    "The area under the ROC curve (AUC-ROC) is a commonly used metric to summarize the overall performance of a classifier. A higher AUC-ROC value indicates better discrimination power and a more accurate classifier. An AUC-ROC of 0.5 suggests a random classifier, while an AUC-ROC of 1 represents a perfect classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
